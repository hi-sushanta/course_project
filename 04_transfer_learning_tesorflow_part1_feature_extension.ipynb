{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-transfer-learning-tesorflow-part1-feature-extension.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 04-Transfer learning with Tensorflow Part 1: Feature Extension\n",
        "We've built a bunch of convolutional neural networks from scratch and they all seem to be learning, however, there is still plenty of room for improvement.\n",
        "\n",
        "To improve our model(s), we could spend a while trying different configurations, adding more layers, changing the learning rate, adjusting the number of neurons per layer and more.\n",
        "\n",
        "However, doing this is very time consuming.\n",
        "\n",
        "Luckily, there's a technique we can use to save time.\n",
        "\n",
        "It's called transfer learning, in other words, taking the patterns (also called weights) another model has learned from another problem and using them for our own problem.\n",
        "\n",
        "There are two main benefits to using transfer learning:\n",
        "\n",
        "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
        "2. Can leverage a working neural network architecture which has already learned patterns on similar data to our own. This often results in achieving great results with less custom data.\n",
        "What this means is, instead of hand-crafting our own neural network architectures or building them from scratch, we can utilise models which have worked for others.\n",
        "\n",
        "And instead of training our own models from scratch on our own datasets, we can take the patterns a model has learned from datasets such as ImageNet (millions of images of different objects) and use them as the foundation of our own. Doing this often leads to getting great results with less data.\n",
        "\n",
        "Over the next few notebooks, we'll see the power of transfer learning in action.\n",
        "\n"
      ],
      "metadata": {
        "id": "hrcnQnB6uodQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading and becoming one with data"
      ],
      "metadata": {
        "id": "YWWJgWT_vaRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get data 10% of (10 food classes all data)\n"
      ],
      "metadata": {
        "id": "aBxxSFA3y2BF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}